{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NLP_Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lkidane/Deep-learning-/blob/NLP/Copy_of_NLP_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Az99b8EBkjBl",
        "colab_type": "text"
      },
      "source": [
        "# Gensim: a package to train and use word vectors\n",
        "\n",
        "Gensim is a Python package that allows to train and use word vectors.\n",
        "A lot of functions for word vectors analysis are implemented by Gensim."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7JcTMktkpm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXIPJcnokv4X",
        "colab_type": "code",
        "outputId": "09a8d5d3-e12d-4dfc-9626-e546edac0911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import gensim.downloader as api\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", \"Conversion of the second argument of issubdtype from\", FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", \"This function is deprecated, use smart_open.open instead. See the migration notes for \", UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", \"arrays to stack must be passed as a\", FutureWarning)\n",
        "\n",
        "# This will load word vectors for a large vocabulary \n",
        "# It should take < 5 minutes\n",
        "wv = api.load('glove-wiki-gigaword-50')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sIZatF3ldF4",
        "colab_type": "text"
      },
      "source": [
        "In the following cell, we download a list of analogies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3EPq3ol10nh",
        "colab_type": "code",
        "outputId": "bed4c761-2396-4d1e-bf3b-3abbdfbdd096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-25 11:09:47--  https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 603955 (590K) [text/plain]\n",
            "Saving to: ‘questions-words.txt’\n",
            "\n",
            "\rquestions-words.txt   0%[                    ]       0  --.-KB/s               \rquestions-words.txt 100%[===================>] 589.80K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-01-25 11:09:47 (11.4 MB/s) - ‘questions-words.txt’ saved [603955/603955]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGHfli3bvpmB",
        "colab_type": "text"
      },
      "source": [
        "In the next cell, we open the downloaded file and take a look to see what it contains.\n",
        "We print the first 5 lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAe8dm4HvsXF",
        "colab_type": "code",
        "outputId": "4e48ae9d-97f4-4c2a-9294-8965fc5078d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "f = open('questions-words.txt', 'r')\n",
        "for line in f.readlines()[:5]:\n",
        "    print(line)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ": capital-common-countries\n",
            "\n",
            "Athens Greece Baghdad Iraq\n",
            "\n",
            "Athens Greece Bangkok Thailand\n",
            "\n",
            "Athens Greece Beijing China\n",
            "\n",
            "Athens Greece Berlin Germany\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWMZfPBevv8q",
        "colab_type": "text"
      },
      "source": [
        "Note that :\n",
        "- Athens is to Greece what Baghdad is to Iraq\n",
        "- Athens is to Greece what Bangkok is to Thailand\n",
        "- Athens is to Greece what Beijing is to China\n",
        "etc...\n",
        "\n",
        "Remember the word analogy task : \n",
        "A is to B what C is to D\n",
        "\n",
        "As we saw before, using word vectors, we can try to guess D using the word vectors of A, B and C !\n",
        "\n",
        "We use the formula :\n",
        "$$B-A + C \\approx D$$\n",
        "\n",
        "For each analogy (A,B,C,D) described in the file \"questions-words.txt\", we can try to :\n",
        "- compute $\\tilde{C} = B-A + C$ with the word vectors\n",
        "- compute the nearest neighbors of $\\tilde{C}$ in the word vectors.\n",
        "- If the nearest neighbor is $C$, we've answered correctly to the analogy, otherwise we didn't.\n",
        "\n",
        "Averaging correct / incorrect answers on each analogies gives us a metric. This metric can be used as an indicator of quality of the word embeddings.\n",
        "\n",
        "In the next cell, we will ask Gensim to compute this metric for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrZCcs4b1a5I",
        "colab_type": "code",
        "outputId": "eaa13a42-e8cc-4a08-8fa2-f50145698fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# This should take approximately 5 minutes\n",
        "\n",
        "start = time.time()\n",
        "results = wv.evaluate_word_analogies(analogies='questions-words.txt')\n",
        "print(f\"Accuracy on the world analogy task {results[0]}\")\n",
        "print(f\"Evaluating this took {time.time() - start}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on the world analogy task 0.463717540798522\n",
            "Evaluating this took 186.21752309799194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xao9cuCwJoH4",
        "colab_type": "text"
      },
      "source": [
        "**TODO FIX THIS**\n",
        "\n",
        "\n",
        "Each word is associated with an index value (between 0 and $n_{words} - 1$).\n",
        "If two words have similar spelling, this information will be lost as the words are replaced with their indices.\n",
        "However, we can see that the model still discovers similar meanings automatically: if I take the two words \"car\" and \"cars\", the model has put these vectors close together. \n",
        "\n",
        "Can you guess why ?\n",
        "\n",
        "**TODO CAR VS HOUSE**\n",
        "\n",
        "Answer: These words appear in similar context. In the corpus there are probably sentences like \"I drive my car on the highway\" and \"They drive their cars on the highway\", which means that \"car\" and \"cars\" both appear in the context [\"drive\", \"highway\"].\n",
        "\n",
        "We can use gensim to check the closest word to a word.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viS4Ecmrk9xQ",
        "colab_type": "code",
        "outputId": "f59d939a-f643-4b03-b244-b3dd1b1879d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(wv.most_similar(positive=['car'], topn=5))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('truck', 0.9208585619926453), ('cars', 0.8870190382003784), ('vehicle', 0.8833684325218201), ('driver', 0.8464018702507019), ('driving', 0.8384189009666443)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDhX8_Jcv5_O",
        "colab_type": "text"
      },
      "source": [
        "Question: What does this do ?\n",
        "\n",
        "**Out of a list of words, this prints the one that is least similar to the others. (We gave example code to do this in the second quizz)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP_VckvXliMp",
        "colab_type": "code",
        "outputId": "97aae066-490d-4a39-fc81-25d0d863e9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "car\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4RPeMlMlsKe",
        "colab_type": "text"
      },
      "source": [
        "## Train your own word vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDd7yHJ5nDIi",
        "colab_type": "text"
      },
      "source": [
        "Download and extract the IMDB Sentiment classification corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVHVQKtanCHn",
        "colab_type": "code",
        "outputId": "27195b97-b115-477e-b974-6eac7ee7f777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar xzf aclImdb_v1.tar.gz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-25 11:13:01--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  42.0MB/s    in 1.9s    \n",
            "\n",
            "2020-01-25 11:13:03 (42.0 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldHMD6ghwBcD",
        "colab_type": "text"
      },
      "source": [
        "In the following cell, we define a class called GensimCorpus. Can you guess what it does ? The code look complicated ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFBGqopKl1f5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import utils\n",
        "import os\n",
        "from os.path import join\n",
        "\n",
        "class GensimCorpus(object):\n",
        "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
        "\n",
        "    def __init__(self, path=\"aclImdb/train/unsup\"):\n",
        "        self.path = path\n",
        "        self.filenames = [fname for fname in os.listdir(path) if fname.endswith(\".txt\")]\n",
        "        \n",
        "\n",
        "    def __iter__(self):\n",
        "        for fname in self.filenames:\n",
        "            # assume there's one document per line, tokens separated by whitespace\n",
        "            with open(join(self.path, fname), \"r\") as f:\n",
        "                lines = f.readlines()\n",
        "                assert len(lines) == 1\n",
        "                line = lines[0].strip()\n",
        "                yield utils.simple_preprocess(line)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1J3mve-wD3T",
        "colab_type": "text"
      },
      "source": [
        "In  order to understand what it does, we will try to use it. ```__iter__ ``` is defined for generators, let's try to see what this generator outputs !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYBJbTQnrHpr",
        "colab_type": "code",
        "outputId": "642c0dfd-ce2c-448f-a618-de3735215d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "sentences = GensimCorpus()  # instanciate this weird object\n",
        "\n",
        "for i, mystery_object in enumerate(sentences):\n",
        "    print(mystery_object)\n",
        "    if i == 5:\n",
        "        break  # we only want to display 5 elements"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['friend', 'of', 'mine', 'made', 'me', 'tape', 'of', 'various', 'stuff', 'this', 'was', 'on', 'it', 'had', 'never', 'even', 'heard', 'of', 'this', 'film', 'before', 'now', 'know', 'why', 'wonder', 'why', 'glitter', 'has', 'lower', 'rating', 'then', 'this', 'drivel', 'but', 'am', 'afraid', 'to', 'watch', 'that', 'film', 'to', 'find', 'out', 'for', 'myself', 'lest', 'wake', 'up', 'in', 'the', 'middle', 'of', 'the', 'night', 'from', 'mariah', 'carey', 'nightmare', 'br', 'br', 'so', 'watched', 'it', 'but', 'watched', 'most', 'of', 'it', 'in', 'fast', 'forward', 'you', 'get', 'the', 'picture', 'that', 'most', 'of', 'the', 'cast', 'are', 'mean', 'people', 'who', 'are', 'going', 'to', 'get', 'it', 'in', 'bad', 'ways', 'as', 'soon', 'as', 'they', 'are', 'introduced', 'br', 'br', 'this', 'is', 'real', 'stinker', 'one', 'of', 'those', 'heavy', 'metal', 'horror', 'films', 'that', 'never', 'should', 'have', 'been', 'conceived', 'the', 'problem', 'is', 'not', 'that', 'the', 'movie', 'is', 'stupid', 'cheesy', 'and', 'inane', 'but', 'that', 'that', 'the', 'movie', 'realizes', 'it', 'is', 'such', 'and', 'still', 'continues', 'to', 'deliver', 'the', 'same', 'old', 'good', 'versus', 'evil', 'confrontation', 'and', 'guess', 'who', 'wins', 'and', 'guess', 'how', 'it', 'ends', 'anyway', 'blah', 'blah', 'blah', 'br', 'br', 'hey', 'like', 'horror', 'films', 'this', 'one', 'is', 'best', 'avoided', 'unless', 'you', 'want', 'to', 'witness', 'some', 'of', 'the', 'worst', 'one', 'liners', 'in', 'hollywood', 'history', 'sigh', 'guess', 'some', 'movie', 'makers', 'forgot', 'that', 'good', 'horror', 'films', 'died', 'back', 'in', 'the', 'br', 'br', 'on', 'the', 'plus', 'side', 'this', 'one', 'would', 'have', 'probably', 'made', 'decent', 'tales', 'from', 'the', 'crypt', 'short', 'it', 'does', 'have', 'very', 'comics', 'feel', 'to', 'it', 'but', 'that', 'is', 'the', 'granny', 'biggest', 'problem', 'it', 'only', 'has', 'minutes', 'of', 'entertainment', 'tops', 'and', 'didn', 'we', 'already', 'see', 'this', 'story', 'in', 'the', 'first', 'tale', 'of', 'tales', 'from', 'the', 'crypt', 'at', 'least', 'that', 'had', 'ed', 'harris', 'getting', 'crushed', 'by', 'tomb', 'stone', 'via', 'zombie', 'telekinesis', 'br', 'br', 'check', 'out', 'night', 'of', 'the', 'demons', 'for', 'better', 'film', 'from', 'this', 'inane', 'sub', 'facet', 'of', 'the', 'horror', 'genre', 'heavy', 'metal', 'evil', 'incarnate', 'it', 'sucks', 'too', 'but', 'at', 'least', 'it', 'didn', 'annoy', 'me', 'check', 'out', 'fulci', 'for', 'some', 'real', 'horror', 'br', 'br']\n",
            "['this', 'movie', 'is', 'disaster', 'from', 'beginning', 'to', 'end', 'and', 'justify', 'my', 'summary', 'because', 'even', 'though', 'it', 'is', 'suppose', 'to', 'be', 'terror', 'movie', 'there', 'is', 'not', 'terror', 'anywhere', 'the', 'idea', 'that', 'normal', 'looking', 'dogs', 'could', 'ever', 'be', 'scary', 'enough', 'just', 'by', 'showing', 'their', 'teeth', 'is', 'something', 'that', 'beggars', 'belief', 'even', 'if', 'genetic', 'experiment', 'was', 'done', 'on', 'the', 'dogs', 'the', 'movie', 'is', 'not', 'scary', 'at', 'any', 'point', 'and', 'look', 'ridiculous', 'but', 'there', 'is', 'something', 'far', 'worse', 'and', 'more', 'sinister', 'in', 'this', 'movie', 'we', 'know', 'they', 'are', 'good', 'friends', 'but', 'it', 'happens', 'that', 'once', 'one', 'of', 'them', 'falls', 'victim', 'to', 'the', 'dogs', 'nobody', 'really', 'seems', 'to', 'care', 'and', 'they', 'are', 'left', 'to', 'their', 'own', 'luck', 'for', 'instance', 'the', 'black', 'guy', 'once', 'he', 'is', 'bitten', 'by', 'two', 'dogs', 'in', 'the', 'cellar', 'they', 'don', 'seem', 'even', 'to', 'try', 'to', 'rescue', 'him', 'from', 'the', 'dogs', 'they', 'shut', 'the', 'door', 'and', 'let', 'the', 'dogs', 'finish', 'him', 'off', 'or', 'the', 'guy', 'they', 'find', 'in', 'the', 'woods', 'wounded', 'is', 'left', 'to', 'be', 'eaten', 'by', 'the', 'dogs', 'this', 'film', 'is', 'not', 'believable', 'at', 'all', 'and', 'has', 'many', 'flaws', 'why', 'doesn', 'anybody', 'grab', 'kitchen', 'knife', 'will', 'not', 'waste', 'any', 'more', 'time', 'on', 'this', 'review', 'll', 'just', 'sum', 'it', 'up', 'the', 'plot', 'is', 'stupid', 'the', 'idea', 'ridiculous', 'not', 'scary', 'at', 'all', 'and', 'full', 'of', 'flaws', 'discontinuity', 'badly', 'written', 'and', 'thought', 'out', 'my', 'vote', 'has', 'to', 'be', 'out', 'of']\n",
            "['henry', 'june', 'has', 'place', 'in', 'film', 'history', 'as', 'the', 'first', 'picture', 'to', 'be', 'rated', 'nc', 'there', 'are', 'films', 'with', 'much', 'more', 'sex', 'nudity', 'and', 'offensive', 'material', 'than', 'this', 'that', 'get', 'in', 'the', 'us', 'br', 'br', 'the', 'film', 'tells', 'the', 'love', 'triangle', 'of', 'henry', 'miller', 'fred', 'ward', 'his', 'wife', 'june', 'the', 'stunning', 'uma', 'thurman', 'and', 'anais', 'nin', 'the', 'equally', 'stunning', 'maria', 'de', 'medeiros', 'there', 'is', 'lots', 'of', 'sex', 'and', 'trips', 'to', 'brothels', 'casual', 'lesbian', 'romance', 'and', 'henry', 'bedhopping', 'between', 'the', 'two', 'leading', 'ladies', 'it', 'is', 'this', 'relaxed', 'sexual', 'freedom', 'that', 'is', 'more', 'the', 'moral', 'center', 'of', 'this', 'movie', 'rather', 'than', 'the', 'sex', 'itself', 'br', 'br', 'there', 'are', 'some', 'very', 'erotic', 'scenes', 'most', 'notably', 'the', 'notorious', 'and', 'famous', 'lesbian', 'encounter', 'between', 'anais', 'and', 'june', 'towards', 'the', 'end', 'it', 'is', 'brilliantly', 'filmed', 'and', 'contains', 'very', 'early', 'wonderful', 'role', 'from', 'kevin', 'spacey', 'playing', 'talkative', 'paranoid', 'loser', 'br', 'br', 'all', 'these', 'good', 'qualities', 'are', 'not', 'binding', 'enough', 'to', 'make', 'coherent', 'drama', 'of', 'this', 'length', 'it', 'drags', 'on', 'and', 'has', 'some', 'completely', 'deletable', 'scenes', 'it', 'provides', 'no', 'real', 'insight', 'into', 'the', 'author', 'as', 'character', 'but', 'merely', 'uses', 'the', 'writers', 'backdrop', 'to', 'tell', 'the', 'love', 'triangle', 'story', 'henry', 'june', 'seems', 'to', 'stop', 'itself', 'short', 'of', 'being', 'purely', 'sexual', 'film', 'or', 'drama', 'but', 'still', 'it', 'is', 'very', 'good', 'love', 'triangle', 'story', 'br', 'br', 'out', 'of', 'br', 'br', 'if', 'you', 'like', 'maria', 'de', 'medeiros', 'here', 'and', 'in', 'pulp', 'fiction', 'then', 'seek', 'out', 'the', 'small', 'spanish', 'film', 'goldenballs']\n",
            "['this', 'was', 'film', 'that', 'got', 'rather', 'high', 'score', 'in', 'the', 'leonard', 'maltin', 'guide', 'saying', 'the', 'film', 'was', 'still', 'potent', 'well', 'was', 'excited', 'about', 'seeing', 'it', 'as', 'love', 'american', 'wwii', 'propaganda', 'films', 'and', 'have', 'seen', 'huge', 'number', 'of', 'them', 'unfortunately', 'while', 'the', 'original', 'stage', 'production', 'of', 'the', 'play', 'and', 'the', 'subsequent', 'movie', 'made', 'quite', 'splash', 'the', 'whole', 'thing', 'seems', 'terribly', 'dated', 'and', 'poorly', 'written', 'today', 'the', 'bottom', 'line', 'is', 'that', 'the', 'film', 'lacks', 'subtlety', 'and', 'has', 'plot', 'holes', 'big', 'enough', 'to', 'fly', 'through', 'them', 'the', 'movie', 'begins', 'well', 'enough', 'as', 'frederic', 'march', 'fine', 'actor', 'is', 'in', 'the', 'lead', 'but', 'my', 'hopes', 'were', 'soon', 'dashed', 'when', 'the', 'little', 'nazi', 'boy', 'emil', 'comes', 'to', 'live', 'with', 'them', 'first', 'it', 'hard', 'to', 'imagine', 'the', 'nazis', 'letting', 'boy', 'leave', 'the', 'country', 'to', 'come', 'to', 'the', 'us', 'while', 'we', 'are', 'at', 'war', 'with', 'them', 'secondly', 'it', 'hard', 'to', 'imagine', 'the', 'us', 'government', 'just', 'accepting', 'the', 'kid', 'without', 'making', 'sure', 'he', 'wasn', 'spy', 'or', 'an', 'america', 'hater', 'but', 'regardless', 'here', 'appears', 'year', 'old', 'boy', 'who', 'often', 'sounds', 'quite', 'german', 'he', 'uses', 'german', 'and', 'english', 'interchangeably', 'but', 'his', 'accent', 'also', 'wavers', 'bit', 'almost', 'sounding', 'swedish', 'or', 'polish', 'from', 'time', 'to', 'time', 'guess', 'you', 'can', 'blame', 'him', 'that', 'much', 'as', 'this', 'is', 'very', 'demanding', 'role', 'for', 'young', 'boy', 'but', 'who', 'you', 'can', 'blame', 'are', 'the', 'writers', 'who', 'immediately', 'throw', 'subtlety', 'out', 'the', 'window', 'instead', 'of', 'the', 'kid', 'pretending', 'to', 'love', 'america', 'or', 'creating', 'trust', 'with', 'his', 'new', 'family', 'he', 'immediately', 'acts', 'like', 'the', 'local', 'chairman', 'of', 'the', 'hitler', 'fan', 'club', 'even', 'showing', 'up', 'to', 'his', 'first', 'meal', 'dressed', 'in', 'full', 'hitler', 'youth', 'regalia', 'including', 'an', 'armband', 'now', 'don', 'know', 'about', 'you', 'but', 'if', 'been', 'alive', 'during', 'the', 'war', 'and', 'kid', 'moved', 'in', 'with', 'me', 'and', 'preceded', 'to', 'parade', 'around', 'the', 'house', 'in', 'nazi', 'uniform', 'spouting', 'hate', 'think', 'be', 'bit', 'peeved', 'but', 'march', 'and', 'the', 'rest', 'try', 'to', 'show', 'him', 'understanding', 'instead', 'of', 'turning', 'the', 'brat', 'over', 'to', 'the', 'fbi', 'plus', 'while', 'march', 'works', 'on', 'top', 'secret', 'military', 'plans', 'he', 'does', 'lousy', 'job', 'of', 'securing', 'them', 'so', 'emil', 'isn', 'able', 'to', 'steal', 'them', 'also', 'you', 'think', 'when', 'he', 'went', 'to', 'school', 'and', 'began', 'spreading', 'hate', 'and', 'nazi', 'propaganda', 'that', 'the', 'school', 'would', 'have', 'taken', 'more', 'notice', 'no', 'trip', 'to', 'the', 'principal', 'office', 'no', 'phone', 'calls', 'home', 'and', 'no', 'contact', 'with', 'the', 'local', 'police', 'it', 'just', 'defies', 'all', 'common', 'sense', 'to', 'think', 'that', 'during', 'the', 'war', 'anyone', 'would', 'have', 'been', 'allowed', 'to', 'act', 'this', 'way', 'without', 'being', 'arrested', 'is', 'crazy', 'america', 'does', 'have', 'freedom', 'of', 'speech', 'but', 'for', 'foreign', 'national', 'spreading', 'pro', 'nazi', 'propaganda', 'during', 'the', 'war', 'this', 'is', 'ridiculous', 'now', 'if', 'this', 'was', 'the', 'only', 'problem', 'with', 'the', 'film', 'guess', 'you', 'could', 'chalk', 'it', 'up', 'to', 'naiveté', 'unfortunately', 'it', 'got', 'lot', 'worse', 'emil', 'spread', 'anger', 'and', 'dissent', 'everywhere', 'but', 'no', 'one', 'actually', 'did', 'anything', 'about', 'this', 'so', 'far', 'so', 'good', 'but', 'after', 'warning', 'signs', 'and', 'when', 'he', 'then', 'tries', 'to', 'kill', 'two', 'people', 'by', 'beating', 'one', 'with', 'fireplace', 'poker', 'and', 'then', 'trying', 'to', 'stab', 'another', 'you', 'think', 'the', 'kid', 'would', 'have', 'been', 'deported', 'or', 'arrested', 'or', 'even', 'shot', 'but', 'in', 'one', 'of', 'the', 'worst', 'endings', 'in', 'film', 'history', 'they', 'stupid', 'family', 'feels', 'sorry', 'for', 'the', 'kid', 'and', 'decides', 'like', 'the', 'beatles', 'once', 'said', 'all', 'you', 'need', 'is', 'love', 'to', 'make', 'matters', 'worse', 'the', 'girl', 'who', 'was', 'beaten', 'with', 'the', 'poker', 'was', 'march', 'own', 'kid', 'and', 'the', 'lady', 'who', 'convinces', 'march', 'not', 'to', 'press', 'charges', 'in', 'the', 'end', 'was', 'his', 'jewish', 'fiancée', 'yecch', 'what', 'drivel', 'the', 'film', 'just', 'doesn', 'make', 'sense', 'and', 'becomes', 'tiresome', 'because', 'of', 'all', 'this']\n",
            "['say', 'what', 'you', 'like', 'about', 'good', 'independent', 'movie', 'or', 'good', 'movie', 'but', 'to', 'me', 'good', 'film', 'like', 'acne', 'beats', 'decent', 'million', 'dollar', 'film', 'every', 'time', 'yes', 'the', 'acting', 'isn', 'as', 'professional', 'with', 'this', 'film', 'but', 'that', 'adds', 'certain', 'realism', 'yes', 'the', 'sets', 'aren', 'always', 'picture', 'perfect', 'but', 'whose', 'house', 'or', 'office', 'is', 'acne', 'is', 'horror', 'movie', 'for', 'and', 'beyond', 'the', 'threats', 'to', 'the', 'main', 'characters', 'are', 'as', 'real', 'as', 'what', 'people', 'face', 'everyday', 'around', 'our', 'planet', 'pollution', 'exploitation', 'manipulation', 'false', 'promises', 'disease', 'and', 'disfigurement', 'but', 'it', 'does', 'so', 'with', 'twisted', 'black', 'comic', 'heart', 'and', 'believe', 'me', 'you', 're', 'going', 'to', 'laugh', 'with', 'the', 'movie']\n",
            "['this', 'is', 'real', 'curiosity', 'from', 'the', 'vaults', 'late', 'swedish', 'sex', 'education', 'film', 'which', 'became', 'an', 'enormous', 'box', 'office', 'hit', 'across', 'europe', 'and', 'even', 'when', 'it', 'was', 'finally', 'released', 'uncut', 'with', 'an', 'certificate', 'in', 'the', 'uk', 'in', 'it', 'was', 'initially', 'refused', 'certificate', 'this', 'is', 'historically', 'interesting', 'as', 'the', 'language', 'of', 'love', 'as', 'it', 'was', 'titled', 'in', 'english', 'speaking', 'markets', 'features', 'some', 'sections', 'of', 'actual', 'hardcore', 'footage', 'with', 'close', 'ups', 'of', 'fingers', 'masturbating', 'vaginas', 'and', 'penis', 'penetrating', 'one', 'the', 'film', 'is', 'apparently', 'meant', 'as', 'serious', 'attempt', 'to', 'allay', 'people', 'fears', 'and', 'misconceptions', 'about', 'sex', 'improve', 'the', 'sex', 'lives', 'of', 'heterosexual', 'couples', 'but', 'undoubtedly', 'the', 'enormous', 'box', 'office', 'success', 'of', 'the', 'film', 'was', 'due', 'to', 'the', 'prurient', 'interest', 'of', 'the', 'public', 'br', 'br', 'it', 'is', 'hard', 'to', 'image', 'people', 'actually', 'sitting', 'in', 'cinema', 'and', 'watching', 'the', 'film', 'the', 'bulk', 'of', 'the', 'footage', 'has', 'four', 'sexperts', 'sex', 'therapists', 'plus', 'gynaecologist', 'sitting', 'around', 'in', 'living', 'room', 'swilling', 'gallons', 'of', 'tea', 'coffee', 'and', 'talking', 'earnestly', 'about', 'sex', 'don', 'know', 'about', 'the', 'time', 'of', 'the', 'film', 'release', 'but', 'these', 'days', 'the', 'sexperts', 'chat', 'is', 'unintentionally', 'hilarious', 'as', 'the', 'foursome', 'are', 'humourless', 'po', 'faced', 'and', 'rather', 'brusque', 'in', 'their', 'talk', 'as', 'well', 'as', 'being', 'an', 'extremely', 'plain', 'verging', 'on', 'ugly', 'bunch', 'br', 'br', 'inter', 'cut', 'with', 'this', 'mirth', 'producing', 'talk', 'are', 'mockumentary', 'scenes', 'purporting', 'to', 'illustrate', 'the', 'findings', 'of', 'famous', 'sex', 'researchers', 'masters', 'and', 'johnson', 'in', 'which', 'couples', 'talk', 'about', 'and', 'do', 'the', 'sex', 'thing', 'here', 'the', 'film', 'falls', 'even', 'further', 'into', 'risibility', 'as', 'although', 'these', 'couples', 'are', 'meant', 'to', 'represent', 'or', 'actually', 'be', 'real', 'people', 'they', 'are', 'so', 'one', 'dimensional', 'robotic', 'and', 'mono', 'subject', 'orientated', 'that', 'they', 'seem', 'like', 'no', 'one', 'anyone', 'has', 'even', 'met', 'in', 'this', 'world', 'rather', 'being', 'dead', 'ringers', 'for', 'the', 'inhabitants', 'of', 'some', 'future', 'brave', 'new', 'world', 'type', 'dystopia', 'the', 'most', 'striking', 'moment', 'comes', 'when', 'the', 'most', 'focused', 'upon', 'couple', 'who', 've', 'previously', 'experienced', 'sexual', 'problems', 'talk', 'to', 'each', 'other', 'after', 'bout', 'of', 'now', 'satisfying', 'sex', 'and', 'tell', 'each', 'other', 'that', 'they', 'are', 'now', 'real', 'two', 'less', 'real', 'people', 'you', 'll', 'have', 'trouble', 'finding', 'in', 'the', 'history', 'of', 'the', 'cinema', 'br', 'br', 'the', 'last', 'third', 'of', 'the', 'film', 'is', 'mostly', 'taken', 'up', 'by', 'the', 'gynaecologist', 'going', 'about', 'his', 'business', 'inserting', 'diaphragms', 'coils', 'and', 'caps', 'into', 'various', 'young', 'women', 'or', 'advising', 'them', 'to', 'go', 'onto', 'the', 'pill', 'this', 'is', 'followed', 'by', 'completely', 'unnecessary', 'montage', 'of', 'shots', 'showing', 'red', 'light', 'district', 'pages', 'from', 'lurid', 'pornographic', 'magazines', 'and', 'couples', 'walking', 'around', 'lewdly', 'all', 'supposedly', 'to', 'illustrate', 'what', 'wrong', 'with', 'society', 'prurient', 'attitude', 'to', 'sex', 'but', 'edited', 'and', 'scored', 'in', 'such', 'way', 'as', 'to', 'encourage', 'an', 'adolescent', 'and', 'voyeuristic', 'attitude', 'br', 'br', 'the', 'film', 'is', 'poorly', 'shot', 'and', 'goes', 'on', 'for', 'too', 'long', 'yet', 'it', 'gets', 'extra', 'stars', 'for', 'its', 'camp', 'value', 'today', 'there', 'also', 'saccharine', 'and', 'quite', 'repulsive', 'score', 'by', 'benny', 'and', 'bjorn', 'pre', 'abba', 'this', 'is', 'btw', 'the', 'film', 'which', 'travis', 'bickle', 'takes', 'betsy', 'to', 'see', 'in', 'taxi', 'driver', 'the', 'fact', 'that', 'she', 'was', 'offended', 'instead', 'of', 'sitting', 'there', 'laughing', 'her', 'head', 'off', 'shows', 'how', 'unsuitable', 'date', 'she', 'was', 'the', 'language', 'of', 'love', 'is', 'little', 'more', 'now', 'than', 'historical', 'document', 'and', 'testament', 'to', 'how', 'self', 'deluding', 'the', 'experts', 'in', 'pseudo', 'sciences', 'can', 'get', 'as', 'they', 'pretend', 'to', 'serious', 'encouragement', 'of', 'healthy', 'loving', 'sex', 'life', 'whilst', 'adding', 'to', 'the', 'creation', 'of', 'culture', 'of', 'voyeurism', 'and', 'conformity']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-APUBdAwIfS",
        "colab_type": "text"
      },
      "source": [
        "Gensim can learn word embeddings ( == word vectors) from a text corpus. Let's learn word embeddings on our GensimCorpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvYkDKq5lvEh",
        "colab_type": "code",
        "outputId": "44910124-e438-445e-f546-91e0d17f0091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import gensim.models\n",
        "\n",
        "# This should take approximately 3 minutes\n",
        "start = time.time()\n",
        "model = gensim.models.Word2Vec(sentences=sentences, size=50)\n",
        "print(\"Took %.2f\" % (time.time() - start))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 147.33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJpNIdik3ZTl",
        "colab_type": "code",
        "outputId": "7c95101e-2e24-4569-ca3e-d45a26dd6ef9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "model[\"was\"].shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jC-Ax6hwK7S",
        "colab_type": "text"
      },
      "source": [
        "The model we learned, ```model``` contains word vectors ```model.wv```. We can use ```evaluate_word_analogies``` as before to evaluate the quality of our newly learned word vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWlSZg4jtDdN",
        "colab_type": "code",
        "outputId": "194dae84-69c1-4c11-8570-d0ce298d80fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# This should take approximately 5 minutes\n",
        "\n",
        "start = time.time()\n",
        "results2 = model.wv.evaluate_word_analogies(analogies='questions-words.txt')\n",
        "\n",
        "print(f\"Accuracy on the world analogy task {results2[0]}\")\n",
        "print(f\"Evaluating this took {time.time() - start}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on the world analogy task 0.1477137514873364\n",
            "Evaluating this took 14.065808534622192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxnU5YmBwOd8",
        "colab_type": "text"
      },
      "source": [
        "What about nearest neighbors ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LWRKJ7ut7Xt",
        "colab_type": "code",
        "outputId": "fe9f2f84-4cb1-4096-f2cb-2c4463059358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(model.wv.most_similar(positive=['king'], topn=5))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('superman', 0.7197271585464478), ('tarzan', 0.6752631664276123), ('wayne', 0.6702644228935242), ('hong', 0.6597945690155029), ('carpenter', 0.6559469699859619)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmKXkGDgVlaN",
        "colab_type": "text"
      },
      "source": [
        "Question: Is this model as accurate as the previous one ?\n",
        "Answer: No. It was trained on a smaller corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khgKL5tv3_WH",
        "colab_type": "code",
        "outputId": "84e36334-8550-4442-9e86-1a1da89c0d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(model.wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "land\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTQ7QHImuQdm",
        "colab_type": "code",
        "outputId": "43b6776c-bdf2-434a-f618-9583337d65df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(wv.most_similar(positive=['car'], topn=5))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('truck', 0.9208585619926453), ('cars', 0.8870190382003784), ('vehicle', 0.8833684325218201), ('driver', 0.8464018702507019), ('driving', 0.8384189009666443)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75I9wu3mKrj9",
        "colab_type": "text"
      },
      "source": [
        "## Text classification with the bag of words model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTuicK6cC_Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positives = GensimCorpus(path=\"aclImdb/train/pos\")\n",
        "negatives = GensimCorpus(path=\"aclImdb/train/neg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBG5Ht2jA04d",
        "colab_type": "text"
      },
      "source": [
        "This function uses the word_vectors to transform the sentences in the corpus into their average word vectors.\n",
        "Notice that we ignore ```w``` if it is not in ```word_vectors```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERqxW8GbHPmG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_embeddings(corpus, word_vectors):\n",
        "  embeddings = []\n",
        "\n",
        "  for sentence in corpus:\n",
        "    embs = [word_vectors[w] for w in sentence if w in word_vectors]\n",
        "    embeddings.append(sum(embs) / len(embs))\n",
        "\n",
        "  return np.stack(embeddings)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgaTMEKGWrbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pos = create_embeddings(positives, model.wv)\n",
        "X_neg = create_embeddings(negatives, model.wv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdZ0ZmRcV57X",
        "colab_type": "code",
        "outputId": "9583a9d4-d30f-4b52-8e2a-9a4a9acaa466",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(X_pos.shape)\n",
        "print(X_neg.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12500, 50)\n",
            "(12500, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW6OYaCJE9sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_pos = X_pos.shape[0]\n",
        "n_neg = X_neg.shape[0]\n",
        "\n",
        "X = np.concatenate([X_pos, X_neg])\n",
        "y = np.zeros((n_pos + n_neg, ), dtype=int)\n",
        "\n",
        "y[:n_pos] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFi6LZPWBC1F",
        "colab_type": "text"
      },
      "source": [
        "Create a train and test set from our embedded (this means transformed into vectors) corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN9iurlaYyD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOFyKYOgZLyd",
        "colab_type": "code",
        "outputId": "91ad5151-ac33-4581-bf06-4099051af3fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#TODO: Sklearn linear classifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "linear_model = LinearSVC()\n",
        "linear_model.fit(X_train, y_train)\n",
        "\n",
        "print(linear_model.score(X_train, y_train))\n",
        "print(linear_model.score(X_test, y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8286666666666667\n",
            "0.832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuSxa_YWBJ16",
        "colab_type": "text"
      },
      "source": [
        "We try to find the best parameter ```C``` to avoid overfitting on a smaller dataset.\n",
        "\n",
        "We use logarithmically spaced ```C```. Here Alex used $2^x$ for linearly spaced $x$. You can also use ```np.logspace```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1BF0tdQLr-k",
        "colab_type": "code",
        "outputId": "a5c9eb63-5fe2-4492-92c3-2b7d1c648d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "n_samp = 100\n",
        "\n",
        "results_train = []\n",
        "results_valid = []\n",
        "\n",
        "Cs = [2**x for x in range(-10, 8)]\n",
        "\n",
        "for C in Cs:\n",
        "    linear_model = LinearSVC(C=C)\n",
        "    linear_model.fit(X_train[:n_samp], y_train[:n_samp])\n",
        "\n",
        "    results_train.append(linear_model.score(X_train[:n_samp], y_train[:n_samp]))\n",
        "    results_valid.append(linear_model.score(X_test, y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuHGSZsCDpPE",
        "colab_type": "text"
      },
      "source": [
        "Below, we plot valid and test accuracy for each parameter $C$. We clearly see overfitting on the right, when the validation accuracy decreases, but the training accuracy still increases (because the model is less and less regularized)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9xiCp9W96GI",
        "colab_type": "code",
        "outputId": "7a4521a7-23ef-4604-956c-180788ba93e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(Cs, results_valid, label=\"valid\")\n",
        "plt.plot(Cs, results_train, label=\"train\")\n",
        "plt.xscale(\"log\")  # Notice the log-scale here since our C are logarithmically spaced !\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa202a17da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8HjWazHE9WK",
        "colab_type": "text"
      },
      "source": [
        "# Language modeling\n",
        "\n",
        "Language modeling is a way to train models to generate text. \n",
        "We will see how to use Pytorch models to do language modeling.\n",
        "\n",
        "First, let's look at a few steps that are necessary for text processing.\n",
        "\n",
        "Code adapted from https://github.com/pytorch/examples/tree/master/word_language_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pB2wTS8MTEd",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "Tokenization creates a dictionary that contains all words, and creates an index for each word. \n",
        "Look at the class Dictionary and Corpus below. \n",
        "What do they do ?\n",
        "\n",
        "**Answer:** Dictionary allows to go from strings to numerical ids and from numerical ids to strings. Remember that first, we associate each word with a unique id, then we map these ids to vectors.\n",
        "\n",
        "Corpus represents a corpus of text by adding all the words to its ```Dictionary``` and then transforming the sentences from lists of words to lists of ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSsiYLO4MMBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from io import open\n",
        "import torch\n",
        "\n",
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        print(path)\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    ids.append(self.dictionary.word2idx[word])\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyRPh4tQIbu5",
        "colab_type": "text"
      },
      "source": [
        "## RNN and LSTM models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgV5NqRVNbcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, num_token, embedding_dim, hidden_dim, num_layers, dropout=0.5):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(num_token, embedding_dim)\n",
        "\n",
        "        if rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers, dropout=dropout)\n",
        "        elif rnn_type == 'RNN':\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers, dropout=dropout)\n",
        "        else:\n",
        "            raise NotImplementedError(\"\"\"Only RNN and LSTM are implemented yet\"\"\")\n",
        "            \n",
        "        self.decoder = nn.Linear(hidden_dim, num_token)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input))\n",
        "\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "\n",
        "        return decoded, hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.num_layers, bsz, self.hidden_dim),\n",
        "                    weight.new_zeros(self.num_layers, bsz, self.hidden_dim))\n",
        "        else:\n",
        "            return weight.new_zeros(self.num_layers, bsz, self.hidden_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1_3nHM8PdsC",
        "colab_type": "text"
      },
      "source": [
        "## Train your own language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUx-TX8NGwAV",
        "colab_type": "code",
        "outputId": "cf949723-384c-4993-d096-a70d2cc6e98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget -O train.txt https://github.com/pytorch/examples/blob/master/word_language_model/data/wikitext-2/train.txt?raw=true\n",
        "!wget -O valid.txt https://github.com/pytorch/examples/blob/master/word_language_model/data/wikitext-2/valid.txt?raw=true\n",
        "!wget -O test.txt https://github.com/pytorch/examples/blob/master/word_language_model/data/wikitext-2/test.txt?raw=true"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-25 11:16:20--  https://github.com/pytorch/examples/blob/master/word_language_model/data/wikitext-2/train.txt?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/pytorch/examples/raw/master/word_language_model/data/wikitext-2/train.txt [following]\n",
            "--2020-01-25 11:16:20--  https://github.com/pytorch/examples/raw/master/word_language_model/data/wikitext-2/train.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/pytorch/examples/master/word_language_model/data/wikitext-2/train.txt [following]\n",
            "--2020-01-25 11:16:20--  https://raw.githubusercontent.com/pytorch/examples/master/word_language_model/data/wikitext-2/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10797148 (10M) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "train.txt           100%[===================>]  10.30M  25.2MB/s    in 0.4s    \n",
            "\n",
            "2020-01-25 11:16:21 (25.2 MB/s) - ‘train.txt’ saved [10797148/10797148]\n",
            "\n",
            "--2020-01-25 11:16:22--  https://github.com/pytorch/examples/blob/master/word_language_model/data/wikitext-2/valid.txt?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/pytorch/examples/raw/master/word_language_model/data/wikitext-2/valid.txt [following]\n",
            "--2020-01-25 11:16:23--  https://github.com/pytorch/examples/raw/master/word_language_model/data/wikitext-2/valid.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/pytorch/examples/master/word_language_model/data/wikitext-2/valid.txt [following]\n",
            "--2020-01-25 11:16:23--  https://raw.githubusercontent.com/pytorch/examples/master/word_language_model/data/wikitext-2/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1121681 (1.1M) [text/plain]\n",
            "Saving to: ‘valid.txt’\n",
            "\n",
            "valid.txt           100%[===================>]   1.07M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-01-25 11:16:23 (12.6 MB/s) - ‘valid.txt’ saved [1121681/1121681]\n",
            "\n",
            "--2020-01-25 11:16:25--  https://github.com/pytorch/examples/blob/master/word_language_model/data/wikitext-2/test.txt?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/pytorch/examples/raw/master/word_language_model/data/wikitext-2/test.txt [following]\n",
            "--2020-01-25 11:16:25--  https://github.com/pytorch/examples/raw/master/word_language_model/data/wikitext-2/test.txt\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/pytorch/examples/master/word_language_model/data/wikitext-2/test.txt [following]\n",
            "--2020-01-25 11:16:25--  https://raw.githubusercontent.com/pytorch/examples/master/word_language_model/data/wikitext-2/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1256449 (1.2M) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "test.txt            100%[===================>]   1.20M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-01-25 11:16:25 (10.1 MB/s) - ‘test.txt’ saved [1256449/1256449]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFACJSMwDOnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "\n",
        "args = argparse.Namespace(\n",
        "  data='.',\n",
        "  model='LSTM',\n",
        "  emsize=200,\n",
        "  nhid=200,\n",
        "  nlayers=2,\n",
        "  lr=20,\n",
        "  clip=0.25,\n",
        "  epochs=20,\n",
        "  batch_size=20,\n",
        "  bptt=35,\n",
        "  dropout=0.2,\n",
        "  seed=1111,\n",
        "  cuda=True,\n",
        "  log_interval=200,\n",
        "  save='model.pt'\n",
        ")\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "if args.cuda:\n",
        "    device = \"cuda:0\"\n",
        "else:\n",
        "    device = \"cpu\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyXPixLIHcDP",
        "colab_type": "code",
        "outputId": "cbd36164-92f1-4c25-eea4-35093242d964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "\n",
        "corpus = Corpus(args.data)\n",
        "\n",
        "# Starting from sequential data, batchify arranges the dataset into columns.\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "# ┌ a g m s ┐\n",
        "# │ b h n t │\n",
        "# │ c i o u │\n",
        "# │ d j p v │\n",
        "# │ e k q w │\n",
        "# └ f l r x ┘.\n",
        "# These columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
        "# batch processing.\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(corpus.train, args.batch_size)\n",
        "val_data = batchify(corpus.valid, eval_batch_size)\n",
        "test_data = batchify(corpus.test, eval_batch_size)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./train.txt\n",
            "./valid.txt\n",
            "./test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf6uwjnrfHpt",
        "colab_type": "text"
      },
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns9nVCoBfE26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ntokens = len(corpus.dictionary)\n",
        "model = RNNModel(args.model, ntokens, args.emsize, args.nhid, args.nlayers, args.dropout).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovIf9ddsfJWN",
        "colab_type": "text"
      },
      "source": [
        "Training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrRaAA8YIMZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        # RNN\n",
        "        return h.detach()\n",
        "    else:\n",
        "        # LSTM \n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "# get_batch subdivides the source data into chunks of length args.bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# ┌ a g m s ┐ ┌ b h n t ┐\n",
        "# └ b h n t ┘ └ c i o u ┘\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(args.bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def evaluate(model, data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    hidden = model.init_hidden(eval_batch_size)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, args.bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            output, hidden = model(data, hidden)\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "\n",
        "    return total_loss / (len(data_source) - 1)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    hidden = model.init_hidden(args.batch_size)\n",
        "\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args.bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "        model.zero_grad()\n",
        "        hidden = repackage_hidden(hidden)\n",
        "        output, hidden = model(data, hidden)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
        "        for p in model.parameters():\n",
        "            p.data.add_(-lr, p.grad.data)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % args.log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / args.log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                epoch, batch, len(train_data) // args.bptt, lr,\n",
        "                elapsed * 1000 / args.log_interval, cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHqEhT9Bfgop",
        "colab_type": "text"
      },
      "source": [
        "### Training loop\n",
        "\n",
        "Training for 20 epochs should take ~15 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CejFqyHbHYdO",
        "colab_type": "code",
        "outputId": "3a1bceec-b959-4268-e30f-2bc3c552cd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Loop over epochs.\n",
        "lr = args.lr\n",
        "best_val_loss = None\n",
        "\n",
        "# At any point you can hit Ctrl + C to break out of training early.\n",
        "try:\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train()\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        print('-' * 89)\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "                'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                           val_loss, math.exp(val_loss)))\n",
        "        print('-' * 89)\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            with open(args.save, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val_loss = val_loss\n",
        "        else:\n",
        "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "            lr /= 4.0\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |   200/ 2983 batches | lr 20.00 | ms/batch 19.68 | loss  7.63 | ppl  2055.87\n",
            "| epoch   1 |   400/ 2983 batches | lr 20.00 | ms/batch 19.12 | loss  6.85 | ppl   945.67\n",
            "| epoch   1 |   600/ 2983 batches | lr 20.00 | ms/batch 18.98 | loss  6.47 | ppl   644.55\n",
            "| epoch   1 |   800/ 2983 batches | lr 20.00 | ms/batch 19.06 | loss  6.28 | ppl   536.38\n",
            "| epoch   1 |  1000/ 2983 batches | lr 20.00 | ms/batch 19.13 | loss  6.14 | ppl   463.47\n",
            "| epoch   1 |  1200/ 2983 batches | lr 20.00 | ms/batch 19.38 | loss  6.05 | ppl   425.27\n",
            "| epoch   1 |  1400/ 2983 batches | lr 20.00 | ms/batch 19.54 | loss  5.95 | ppl   382.23\n",
            "| epoch   1 |  1600/ 2983 batches | lr 20.00 | ms/batch 19.34 | loss  5.94 | ppl   380.31\n",
            "| epoch   1 |  1800/ 2983 batches | lr 20.00 | ms/batch 19.65 | loss  5.81 | ppl   334.16\n",
            "| epoch   1 |  2000/ 2983 batches | lr 20.00 | ms/batch 19.72 | loss  5.78 | ppl   324.48\n",
            "| epoch   1 |  2200/ 2983 batches | lr 20.00 | ms/batch 19.92 | loss  5.66 | ppl   287.93\n",
            "| epoch   1 |  2400/ 2983 batches | lr 20.00 | ms/batch 19.97 | loss  5.67 | ppl   291.23\n",
            "| epoch   1 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.14 | loss  5.66 | ppl   286.19\n",
            "| epoch   1 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  5.55 | ppl   256.02\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 61.02s | valid loss  5.56 | valid ppl   259.97\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type RNNModel. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch   2 |   200/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  5.55 | ppl   256.31\n",
            "| epoch   2 |   400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  5.53 | ppl   252.68\n",
            "| epoch   2 |   600/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  5.35 | ppl   211.12\n",
            "| epoch   2 |   800/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  5.37 | ppl   215.02\n",
            "| epoch   2 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  5.35 | ppl   209.95\n",
            "| epoch   2 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  5.33 | ppl   207.23\n",
            "| epoch   2 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  5.33 | ppl   206.24\n",
            "| epoch   2 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.39 | ppl   219.16\n",
            "| epoch   2 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  5.27 | ppl   193.49\n",
            "| epoch   2 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.28 | ppl   195.51\n",
            "| epoch   2 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.18 | ppl   177.75\n",
            "| epoch   2 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  5.21 | ppl   183.12\n",
            "| epoch   2 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  5.22 | ppl   185.53\n",
            "| epoch   2 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  5.14 | ppl   170.65\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 62.86s | valid loss  5.29 | valid ppl   198.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2983 batches | lr 20.00 | ms/batch 20.29 | loss  5.19 | ppl   179.41\n",
            "| epoch   3 |   400/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.21 | ppl   182.18\n",
            "| epoch   3 |   600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.02 | ppl   152.04\n",
            "| epoch   3 |   800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.07 | ppl   158.81\n",
            "| epoch   3 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  5.06 | ppl   158.33\n",
            "| epoch   3 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  5.06 | ppl   157.98\n",
            "| epoch   3 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.08 | ppl   161.54\n",
            "| epoch   3 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.15 | ppl   172.68\n",
            "| epoch   3 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  5.03 | ppl   152.77\n",
            "| epoch   3 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  5.05 | ppl   155.56\n",
            "| epoch   3 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  4.96 | ppl   142.72\n",
            "| epoch   3 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.99 | ppl   147.20\n",
            "| epoch   3 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  5.02 | ppl   151.44\n",
            "| epoch   3 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.94 | ppl   139.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 62.95s | valid loss  5.20 | valid ppl   181.87\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |   200/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  5.00 | ppl   148.88\n",
            "| epoch   4 |   400/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  5.02 | ppl   152.04\n",
            "| epoch   4 |   600/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.84 | ppl   126.86\n",
            "| epoch   4 |   800/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.90 | ppl   133.84\n",
            "| epoch   4 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.90 | ppl   134.41\n",
            "| epoch   4 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.90 | ppl   134.18\n",
            "| epoch   4 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.93 | ppl   138.85\n",
            "| epoch   4 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  5.01 | ppl   150.17\n",
            "| epoch   4 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.89 | ppl   132.54\n",
            "| epoch   4 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.92 | ppl   136.42\n",
            "| epoch   4 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.82 | ppl   123.82\n",
            "| epoch   4 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.85 | ppl   128.38\n",
            "| epoch   4 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.88 | ppl   131.66\n",
            "| epoch   4 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  4.81 | ppl   122.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time: 62.87s | valid loss  5.14 | valid ppl   170.81\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |   200/ 2983 batches | lr 20.00 | ms/batch 20.26 | loss  4.88 | ppl   131.33\n",
            "| epoch   5 |   400/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  4.91 | ppl   134.97\n",
            "| epoch   5 |   600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.72 | ppl   112.47\n",
            "| epoch   5 |   800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.78 | ppl   119.57\n",
            "| epoch   5 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.78 | ppl   118.96\n",
            "| epoch   5 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.79 | ppl   120.41\n",
            "| epoch   5 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.83 | ppl   125.02\n",
            "| epoch   5 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.91 | ppl   135.39\n",
            "| epoch   5 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.79 | ppl   119.77\n",
            "| epoch   5 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.81 | ppl   123.09\n",
            "| epoch   5 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.72 | ppl   111.93\n",
            "| epoch   5 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.76 | ppl   116.28\n",
            "| epoch   5 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.78 | ppl   119.41\n",
            "| epoch   5 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.72 | ppl   111.68\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time: 62.86s | valid loss  5.05 | valid ppl   156.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |   200/ 2983 batches | lr 20.00 | ms/batch 20.26 | loss  4.79 | ppl   119.71\n",
            "| epoch   6 |   400/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.80 | ppl   122.08\n",
            "| epoch   6 |   600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.63 | ppl   102.34\n",
            "| epoch   6 |   800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.69 | ppl   108.83\n",
            "| epoch   6 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.70 | ppl   109.61\n",
            "| epoch   6 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.71 | ppl   110.51\n",
            "| epoch   6 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.75 | ppl   115.53\n",
            "| epoch   6 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.24 | loss  4.83 | ppl   125.18\n",
            "| epoch   6 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.18 | loss  4.70 | ppl   110.14\n",
            "| epoch   6 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.74 | ppl   114.68\n",
            "| epoch   6 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.63 | ppl   102.97\n",
            "| epoch   6 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.68 | ppl   107.54\n",
            "| epoch   6 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  4.71 | ppl   111.26\n",
            "| epoch   6 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.64 | ppl   103.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time: 62.94s | valid loss  5.03 | valid ppl   153.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |   200/ 2983 batches | lr 20.00 | ms/batch 20.32 | loss  4.70 | ppl   110.14\n",
            "| epoch   7 |   400/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.73 | ppl   113.56\n",
            "| epoch   7 |   600/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.55 | ppl    95.10\n",
            "| epoch   7 |   800/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.62 | ppl   101.18\n",
            "| epoch   7 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.63 | ppl   102.12\n",
            "| epoch   7 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.63 | ppl   102.92\n",
            "| epoch   7 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.68 | ppl   107.64\n",
            "| epoch   7 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.76 | ppl   117.23\n",
            "| epoch   7 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.18 | loss  4.64 | ppl   103.43\n",
            "| epoch   7 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.68 | ppl   107.46\n",
            "| epoch   7 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.57 | ppl    96.69\n",
            "| epoch   7 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.61 | ppl   100.19\n",
            "| epoch   7 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.64 | ppl   103.75\n",
            "| epoch   7 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.58 | ppl    97.78\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time: 62.88s | valid loss  5.02 | valid ppl   151.73\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |   200/ 2983 batches | lr 20.00 | ms/batch 20.28 | loss  4.64 | ppl   103.98\n",
            "| epoch   8 |   400/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.67 | ppl   106.70\n",
            "| epoch   8 |   600/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.50 | ppl    89.78\n",
            "| epoch   8 |   800/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  4.56 | ppl    95.20\n",
            "| epoch   8 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.18 | loss  4.57 | ppl    96.68\n",
            "| epoch   8 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.18 | loss  4.58 | ppl    97.55\n",
            "| epoch   8 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.62 | ppl   101.60\n",
            "| epoch   8 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.71 | ppl   110.68\n",
            "| epoch   8 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.59 | ppl    98.04\n",
            "| epoch   8 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  4.62 | ppl   101.64\n",
            "| epoch   8 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.52 | ppl    91.51\n",
            "| epoch   8 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.56 | ppl    95.65\n",
            "| epoch   8 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.59 | ppl    98.10\n",
            "| epoch   8 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.53 | ppl    92.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time: 62.93s | valid loss  4.99 | valid ppl   147.22\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |   200/ 2983 batches | lr 20.00 | ms/batch 20.34 | loss  4.59 | ppl    98.76\n",
            "| epoch   9 |   400/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.62 | ppl   101.28\n",
            "| epoch   9 |   600/ 2983 batches | lr 20.00 | ms/batch 20.24 | loss  4.45 | ppl    85.33\n",
            "| epoch   9 |   800/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.51 | ppl    90.64\n",
            "| epoch   9 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.52 | ppl    92.23\n",
            "| epoch   9 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.53 | ppl    92.86\n",
            "| epoch   9 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.57 | ppl    97.01\n",
            "| epoch   9 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.66 | ppl   105.37\n",
            "| epoch   9 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.54 | ppl    94.02\n",
            "| epoch   9 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.57 | ppl    96.54\n",
            "| epoch   9 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.47 | ppl    87.48\n",
            "| epoch   9 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.51 | ppl    91.05\n",
            "| epoch   9 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.55 | ppl    94.50\n",
            "| epoch   9 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.48 | ppl    88.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time: 62.90s | valid loss  4.98 | valid ppl   145.96\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |   200/ 2983 batches | lr 20.00 | ms/batch 20.28 | loss  4.55 | ppl    94.32\n",
            "| epoch  10 |   400/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.58 | ppl    97.21\n",
            "| epoch  10 |   600/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.40 | ppl    81.67\n",
            "| epoch  10 |   800/ 2983 batches | lr 20.00 | ms/batch 20.23 | loss  4.47 | ppl    87.14\n",
            "| epoch  10 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.49 | ppl    89.05\n",
            "| epoch  10 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.15 | loss  4.49 | ppl    88.80\n",
            "| epoch  10 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.18 | loss  4.53 | ppl    93.09\n",
            "| epoch  10 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.62 | ppl   101.30\n",
            "| epoch  10 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.50 | ppl    90.45\n",
            "| epoch  10 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.54 | ppl    93.40\n",
            "| epoch  10 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.18 | loss  4.43 | ppl    84.20\n",
            "| epoch  10 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.47 | ppl    87.79\n",
            "| epoch  10 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.51 | ppl    90.57\n",
            "| epoch  10 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.45 | ppl    85.59\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 62.88s | valid loss  4.97 | valid ppl   144.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  11 |   200/ 2983 batches | lr 20.00 | ms/batch 20.28 | loss  4.51 | ppl    91.20\n",
            "| epoch  11 |   400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.54 | ppl    93.51\n",
            "| epoch  11 |   600/ 2983 batches | lr 20.00 | ms/batch 20.19 | loss  4.37 | ppl    78.88\n",
            "| epoch  11 |   800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.43 | ppl    83.83\n",
            "| epoch  11 |  1000/ 2983 batches | lr 20.00 | ms/batch 20.24 | loss  4.45 | ppl    85.79\n",
            "| epoch  11 |  1200/ 2983 batches | lr 20.00 | ms/batch 20.17 | loss  4.45 | ppl    86.02\n",
            "| epoch  11 |  1400/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.50 | ppl    89.62\n",
            "| epoch  11 |  1600/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.58 | ppl    97.49\n",
            "| epoch  11 |  1800/ 2983 batches | lr 20.00 | ms/batch 20.22 | loss  4.47 | ppl    87.43\n",
            "| epoch  11 |  2000/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.51 | ppl    90.57\n",
            "| epoch  11 |  2200/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.40 | ppl    81.54\n",
            "| epoch  11 |  2400/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.43 | ppl    84.35\n",
            "| epoch  11 |  2600/ 2983 batches | lr 20.00 | ms/batch 20.21 | loss  4.47 | ppl    87.60\n",
            "| epoch  11 |  2800/ 2983 batches | lr 20.00 | ms/batch 20.20 | loss  4.41 | ppl    82.37\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time: 62.85s | valid loss  4.97 | valid ppl   144.39\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |   200/ 2983 batches | lr 5.00 | ms/batch 20.34 | loss  4.52 | ppl    91.78\n",
            "| epoch  12 |   400/ 2983 batches | lr 5.00 | ms/batch 20.17 | loss  4.51 | ppl    90.79\n",
            "| epoch  12 |   600/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.33 | ppl    75.96\n",
            "| epoch  12 |   800/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.39 | ppl    80.66\n",
            "| epoch  12 |  1000/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.38 | ppl    79.93\n",
            "| epoch  12 |  1200/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.36 | ppl    78.38\n",
            "| epoch  12 |  1400/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.38 | ppl    80.09\n",
            "| epoch  12 |  1600/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.44 | ppl    84.64\n",
            "| epoch  12 |  1800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.32 | ppl    75.50\n",
            "| epoch  12 |  2000/ 2983 batches | lr 5.00 | ms/batch 20.18 | loss  4.35 | ppl    77.19\n",
            "| epoch  12 |  2200/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.22 | ppl    67.95\n",
            "| epoch  12 |  2400/ 2983 batches | lr 5.00 | ms/batch 20.17 | loss  4.24 | ppl    69.21\n",
            "| epoch  12 |  2600/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.26 | ppl    70.80\n",
            "| epoch  12 |  2800/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.18 | ppl    65.63\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time: 62.85s | valid loss  4.84 | valid ppl   126.18\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |   200/ 2983 batches | lr 5.00 | ms/batch 20.39 | loss  4.38 | ppl    79.83\n",
            "| epoch  13 |   400/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.39 | ppl    80.93\n",
            "| epoch  13 |   600/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.22 | ppl    67.92\n",
            "| epoch  13 |   800/ 2983 batches | lr 5.00 | ms/batch 20.17 | loss  4.28 | ppl    72.36\n",
            "| epoch  13 |  1000/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.28 | ppl    72.56\n",
            "| epoch  13 |  1200/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.28 | ppl    72.05\n",
            "| epoch  13 |  1400/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.31 | ppl    74.64\n",
            "| epoch  13 |  1600/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.38 | ppl    79.53\n",
            "| epoch  13 |  1800/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.26 | ppl    71.08\n",
            "| epoch  13 |  2000/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.30 | ppl    73.60\n",
            "| epoch  13 |  2200/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.18 | ppl    65.08\n",
            "| epoch  13 |  2400/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.20 | ppl    66.73\n",
            "| epoch  13 |  2600/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.23 | ppl    68.53\n",
            "| epoch  13 |  2800/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.16 | ppl    64.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time: 62.91s | valid loss  4.83 | valid ppl   125.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |   200/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.33 | ppl    75.60\n",
            "| epoch  14 |   400/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.34 | ppl    77.07\n",
            "| epoch  14 |   600/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.17 | ppl    64.59\n",
            "| epoch  14 |   800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.23 | ppl    68.67\n",
            "| epoch  14 |  1000/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.24 | ppl    69.63\n",
            "| epoch  14 |  1200/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.24 | ppl    69.70\n",
            "| epoch  14 |  1400/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.27 | ppl    71.77\n",
            "| epoch  14 |  1600/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.34 | ppl    76.80\n",
            "| epoch  14 |  1800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.23 | ppl    68.97\n",
            "| epoch  14 |  2000/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.27 | ppl    71.21\n",
            "| epoch  14 |  2200/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.15 | ppl    63.43\n",
            "| epoch  14 |  2400/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.17 | ppl    64.97\n",
            "| epoch  14 |  2600/ 2983 batches | lr 5.00 | ms/batch 20.18 | loss  4.20 | ppl    66.78\n",
            "| epoch  14 |  2800/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.15 | ppl    63.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time: 62.84s | valid loss  4.82 | valid ppl   124.55\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |   200/ 2983 batches | lr 5.00 | ms/batch 20.31 | loss  4.29 | ppl    73.28\n",
            "| epoch  15 |   400/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.31 | ppl    74.55\n",
            "| epoch  15 |   600/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.13 | ppl    62.42\n",
            "| epoch  15 |   800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.19 | ppl    66.27\n",
            "| epoch  15 |  1000/ 2983 batches | lr 5.00 | ms/batch 20.18 | loss  4.21 | ppl    67.62\n",
            "| epoch  15 |  1200/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.22 | ppl    67.78\n",
            "| epoch  15 |  1400/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.25 | ppl    70.06\n",
            "| epoch  15 |  1600/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.31 | ppl    74.78\n",
            "| epoch  15 |  1800/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.20 | ppl    66.99\n",
            "| epoch  15 |  2000/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.24 | ppl    69.50\n",
            "| epoch  15 |  2200/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.13 | ppl    62.24\n",
            "| epoch  15 |  2400/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.15 | ppl    63.47\n",
            "| epoch  15 |  2600/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.19 | ppl    65.94\n",
            "| epoch  15 |  2800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.13 | ppl    62.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time: 62.85s | valid loss  4.82 | valid ppl   124.53\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |   200/ 2983 batches | lr 5.00 | ms/batch 20.25 | loss  4.26 | ppl    71.02\n",
            "| epoch  16 |   400/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.29 | ppl    72.68\n",
            "| epoch  16 |   600/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.10 | ppl    60.60\n",
            "| epoch  16 |   800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.17 | ppl    64.73\n",
            "| epoch  16 |  1000/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.19 | ppl    65.88\n",
            "| epoch  16 |  1200/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.19 | ppl    66.14\n",
            "| epoch  16 |  1400/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.23 | ppl    68.42\n",
            "| epoch  16 |  1600/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.30 | ppl    73.56\n",
            "| epoch  16 |  1800/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.19 | ppl    65.93\n",
            "| epoch  16 |  2000/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.23 | ppl    68.42\n",
            "| epoch  16 |  2200/ 2983 batches | lr 5.00 | ms/batch 20.23 | loss  4.11 | ppl    60.88\n",
            "| epoch  16 |  2400/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.13 | ppl    62.40\n",
            "| epoch  16 |  2600/ 2983 batches | lr 5.00 | ms/batch 20.23 | loss  4.17 | ppl    64.77\n",
            "| epoch  16 |  2800/ 2983 batches | lr 5.00 | ms/batch 20.17 | loss  4.11 | ppl    60.80\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time: 62.89s | valid loss  4.82 | valid ppl   123.78\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |   200/ 2983 batches | lr 5.00 | ms/batch 20.29 | loss  4.24 | ppl    69.33\n",
            "| epoch  17 |   400/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.26 | ppl    70.52\n",
            "| epoch  17 |   600/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.08 | ppl    59.38\n",
            "| epoch  17 |   800/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.15 | ppl    63.42\n",
            "| epoch  17 |  1000/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.17 | ppl    64.45\n",
            "| epoch  17 |  1200/ 2983 batches | lr 5.00 | ms/batch 20.17 | loss  4.17 | ppl    64.81\n",
            "| epoch  17 |  1400/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.21 | ppl    67.28\n",
            "| epoch  17 |  1600/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.27 | ppl    71.75\n",
            "| epoch  17 |  1800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.17 | ppl    64.49\n",
            "| epoch  17 |  2000/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.20 | ppl    66.67\n",
            "| epoch  17 |  2200/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.09 | ppl    59.96\n",
            "| epoch  17 |  2400/ 2983 batches | lr 5.00 | ms/batch 20.24 | loss  4.12 | ppl    61.52\n",
            "| epoch  17 |  2600/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.15 | ppl    63.70\n",
            "| epoch  17 |  2800/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.09 | ppl    59.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time: 62.91s | valid loss  4.81 | valid ppl   123.32\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |   200/ 2983 batches | lr 5.00 | ms/batch 20.26 | loss  4.22 | ppl    67.93\n",
            "| epoch  18 |   400/ 2983 batches | lr 5.00 | ms/batch 20.17 | loss  4.24 | ppl    69.14\n",
            "| epoch  18 |   600/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.06 | ppl    58.02\n",
            "| epoch  18 |   800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.13 | ppl    62.12\n",
            "| epoch  18 |  1000/ 2983 batches | lr 5.00 | ms/batch 20.18 | loss  4.15 | ppl    63.38\n",
            "| epoch  18 |  1200/ 2983 batches | lr 5.00 | ms/batch 20.19 | loss  4.15 | ppl    63.73\n",
            "| epoch  18 |  1400/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.19 | ppl    65.95\n",
            "| epoch  18 |  1600/ 2983 batches | lr 5.00 | ms/batch 20.18 | loss  4.25 | ppl    70.43\n",
            "| epoch  18 |  1800/ 2983 batches | lr 5.00 | ms/batch 20.20 | loss  4.15 | ppl    63.39\n",
            "| epoch  18 |  2000/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.19 | ppl    65.79\n",
            "| epoch  18 |  2200/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.08 | ppl    58.98\n",
            "| epoch  18 |  2400/ 2983 batches | lr 5.00 | ms/batch 20.21 | loss  4.10 | ppl    60.39\n",
            "| epoch  18 |  2600/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.14 | ppl    62.66\n",
            "| epoch  18 |  2800/ 2983 batches | lr 5.00 | ms/batch 20.22 | loss  4.08 | ppl    59.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time: 62.84s | valid loss  4.82 | valid ppl   123.90\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |   200/ 2983 batches | lr 1.25 | ms/batch 20.29 | loss  4.24 | ppl    69.75\n",
            "| epoch  19 |   400/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.27 | ppl    71.29\n",
            "| epoch  19 |   600/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.09 | ppl    59.69\n",
            "| epoch  19 |   800/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.17 | ppl    64.58\n",
            "| epoch  19 |  1000/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.17 | ppl    65.04\n",
            "| epoch  19 |  1200/ 2983 batches | lr 1.25 | ms/batch 20.21 | loss  4.15 | ppl    63.38\n",
            "| epoch  19 |  1400/ 2983 batches | lr 1.25 | ms/batch 20.21 | loss  4.18 | ppl    65.53\n",
            "| epoch  19 |  1600/ 2983 batches | lr 1.25 | ms/batch 20.21 | loss  4.24 | ppl    69.58\n",
            "| epoch  19 |  1800/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.13 | ppl    62.45\n",
            "| epoch  19 |  2000/ 2983 batches | lr 1.25 | ms/batch 20.19 | loss  4.16 | ppl    64.35\n",
            "| epoch  19 |  2200/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.05 | ppl    57.47\n",
            "| epoch  19 |  2400/ 2983 batches | lr 1.25 | ms/batch 20.22 | loss  4.06 | ppl    58.10\n",
            "| epoch  19 |  2600/ 2983 batches | lr 1.25 | ms/batch 20.21 | loss  4.10 | ppl    60.14\n",
            "| epoch  19 |  2800/ 2983 batches | lr 1.25 | ms/batch 20.24 | loss  4.03 | ppl    56.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time: 62.85s | valid loss  4.78 | valid ppl   118.97\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |   200/ 2983 batches | lr 1.25 | ms/batch 20.24 | loss  4.22 | ppl    67.81\n",
            "| epoch  20 |   400/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.22 | ppl    68.32\n",
            "| epoch  20 |   600/ 2983 batches | lr 1.25 | ms/batch 20.18 | loss  4.06 | ppl    57.69\n",
            "| epoch  20 |   800/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.12 | ppl    61.66\n",
            "| epoch  20 |  1000/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.15 | ppl    63.19\n",
            "| epoch  20 |  1200/ 2983 batches | lr 1.25 | ms/batch 20.22 | loss  4.13 | ppl    62.10\n",
            "| epoch  20 |  1400/ 2983 batches | lr 1.25 | ms/batch 20.21 | loss  4.16 | ppl    64.26\n",
            "| epoch  20 |  1600/ 2983 batches | lr 1.25 | ms/batch 20.19 | loss  4.22 | ppl    68.36\n",
            "| epoch  20 |  1800/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.12 | ppl    61.32\n",
            "| epoch  20 |  2000/ 2983 batches | lr 1.25 | ms/batch 20.23 | loss  4.15 | ppl    63.50\n",
            "| epoch  20 |  2200/ 2983 batches | lr 1.25 | ms/batch 20.17 | loss  4.04 | ppl    57.03\n",
            "| epoch  20 |  2400/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.06 | ppl    57.82\n",
            "| epoch  20 |  2600/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.09 | ppl    59.63\n",
            "| epoch  20 |  2800/ 2983 batches | lr 1.25 | ms/batch 20.20 | loss  4.02 | ppl    55.95\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 62.84s | valid loss  4.78 | valid ppl   118.71\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUbNa3uPJRsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "05cc53c8-09a4-42e8-8b25-be1f07c62bbd"
      },
      "source": [
        "# Run on test data.\n",
        "test_loss = evaluate(model, test_data)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, math.exp(test_loss)))\n",
        "print('=' * 89)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  4.71 | test ppl   111.42\n",
            "=========================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MBsi_IpPiTr",
        "colab_type": "text"
      },
      "source": [
        "## Generate sentences with a trained language model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L3kuXeePksh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "5d0aa526-3a4e-4c8b-9f17-36b8bfbe9897"
      },
      "source": [
        "args.words = 200\n",
        "args.temperature = 1\n",
        "\n",
        "model.eval()\n",
        "\n",
        "ntokens = len(corpus.dictionary)\n",
        "\n",
        "hidden = model.init_hidden(1)\n",
        "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "\n",
        "text = []\n",
        "with torch.no_grad():  # no tracking history\n",
        "    for i in range(args.words):\n",
        "        output, hidden = model(input, hidden)\n",
        "        word_weights = output.squeeze().div(args.temperature).exp().cpu()\n",
        "        word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "        input.fill_(word_idx)\n",
        "\n",
        "        word = corpus.dictionary.idx2word[word_idx]\n",
        "        text.append(word)\n",
        "\n",
        "        if i % args.log_interval == 0:\n",
        "            print('| Generated {}/{} words'.format(i, args.words))\n",
        "\n",
        "print(\" \".join(text))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Generated 0/200 words\n",
            "whose own wish to enter the bouquet of Reese . <eos> South of the organization comes ashore , : \" In good history , many <unk> starts , one of the largest Northern readers in America series , this time , and the new . \" Peter Tiny 's Andrew Wat was acting on 30 March 1890 . It was too late in the words that was ongoing early in the first half of 37 – 74 , due to his break as they were about ; he was given the work of a dislike for her child , whilst \" The Ballad of British crime \" is strange , but others include another of the fictional football LP by winning the way , possibly deals , and the following day . Now he made it great album he out of freshness . Ned critic Will <unk> wrote that the scene was inspired by his depiction of an alien , hard history of Wolf and melodic dynamics , the faithful , making the \" <unk> \" against the music system . <eos> The drum air readiness should be given originally of V Corps in the magazine and couple later the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vicSvGicGcw",
        "colab_type": "text"
      },
      "source": [
        "## Demo of the best language models\n",
        "\n",
        "https://transformer.huggingface.co/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtXjgeJKZcIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}